<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
	<meta charset='UTF-8'>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>core/PGanswermacros.pl</title>
	<link rel="shortcut icon" href="/favicon.ico">
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link href="https://openwebwork.github.io/pg-docs/pod/assets/podviewer.css" rel="stylesheet">
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" defer></script>
	<script src="https://openwebwork.github.io/pg-docs/pod/assets/podviewer.js" defer></script>
</head>
<body>
	<div class="pod-header navbar navbar-dark bg-primary px-3 position-fixed border-bottom border-dark">
		<div class="container-fluid d-flex flex-column d-md-block">
			<h1 class="navbar-brand fw-bold fs-5 me-auto me-md-0 mb-2 mb-md-0">core/PGanswermacros.pl</h1>
			<button class="navbar-toggler d-md-none me-auto" type="button" data-bs-toggle="offcanvas"
				data-bs-target="#sidebar" aria-controls="sidebar" aria-label="Toggle Sidebar">
				<span class="navbar-toggler-icon"></span>
			</button>
		</div>
	</div>
	<aside class="offcanvas-md offcanvas-start border-end border-dark position-fixed" tabindex="-1"
		id="sidebar" aria-labelledby="sidebar-label">
		<div class="offcanvas-header">
			<h2 class="offcanvas-title" id="sidebar-label">Index</h2>
			<button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#sidebar"
			   	aria-label="Close">
			</button>
		</div>
		<div class="offcanvas-body p-md-3 w-100">
			<nav>
				<ul class="nav flex-column w-100">
					<li class="nav-item">
						<a href="https://openwebwork.github.io/pg-docs/pod" class="nav-link p-0">WeBWorK POD Home</a>
					</li>
					<li class="nav-item">
						<a href="http://webwork.maa.org/wiki/WeBWorK_Main_Page" class="nav-link p-0">WeBWorK Wiki</a>
					</li>
					<li><hr></li>
<li class="nav-item"><a class="nav-link p-0" href="#NAME">NAME</a></li><li class="nav-item"><a class="nav-link p-0" href="#SYNOPSIS">SYNOPSIS</a></li><li class="nav-item"><a class="nav-link p-0" href="#DESCRIPTION">DESCRIPTION</a></li><li class="nav-item"><a class="nav-link p-0" href="#FUNCTIONS">FUNCTIONS</a>
    <ul class="nav flex-column w-100">
      <li class="nav-item"><a class="nav-link p-0" href="#Answer-evaluator-macros">Answer evaluator macros</a></li>
      <li class="nav-item"><a class="nav-link p-0" href="#Filters">Filters</a>
        <ul class="nav flex-column w-100">
          <li class="nav-item"><a class="nav-link p-0" href="#compare_numbers">compare_numbers</a></li>
          <li class="nav-item"><a class="nav-link p-0" href="#std_num_filter">std_num_filter</a></li>
          <li class="nav-item"><a class="nav-link p-0" href="#std_num_array_filter">std_num_array_filter</a></li>
        </ul>
      </li>
      <li class="nav-item"><a class="nav-link p-0" href="#function_from_string2">function_from_string2</a></li>
      <li class="nav-item"><a class="nav-link p-0" href="#is_zero_array">is_zero_array</a></li>
      <li class="nav-item"><a class="nav-link p-0" href="#best_approx_parameters">best_approx_parameters</a>
        <ul class="nav flex-column w-100">
          <li class="nav-item">
            <ul class="nav flex-column w-100">
              <li class="nav-item"><a class="nav-link p-0" href="#calculate_difference_vector">calculate_difference_vector</a></li>
            </ul>
          </li>
          <li class="nav-item"><a class="nav-link p-0" href="#fix_answer_for_display">fix_answer_for_display</a></li>
          <li class="nav-item"><a class="nav-link p-0" href="#evaluatesToNumber">evaluatesToNumber</a>
            <ul class="nav flex-column w-100">
              <li class="nav-item"><a class="nav-link p-0" href="#is_numeric_expression">is_numeric_expression</a></li>
            </ul>
          </li>
          <li class="nav-item"><a class="nav-link p-0" href="#is_a_number">is_a_number</a></li>
          <li class="nav-item"><a class="nav-link p-0" href="#is_a_fraction">is_a_fraction</a></li>
          <li class="nav-item"><a class="nav-link p-0" href="#phase_pi">phase_pi</a>
            <ul class="nav flex-column w-100">
              <li class="nav-item"><a class="nav-link p-0" href="#is_an_arithemetic_expression">is_an_arithemetic_expression</a></li>
            </ul>
          </li>
          <li class="nav-item"><a class="nav-link p-0" href="#math_constants">math_constants</a></li>
          <li class="nav-item"><a class="nav-link p-0" href="#is_array">is_array</a></li>
          <li class="nav-item"><a class="nav-link p-0" href="#check_syntax">check_syntax</a></li>
          <li class="nav-item"><a class="nav-link p-0" href="#check_strings">check_strings</a></li>
          <li class="nav-item"><a class="nav-link p-0" href="#check_units">check_units</a></li>
          <li class="nav-item"><a class="nav-link p-0" href="#std_problem_grader">std_problem_grader</a></li>
          <li class="nav-item"><a class="nav-link p-0" href="#std_problem_grader2">std_problem_grader2</a></li>
          <li class="nav-item"><a class="nav-link p-0" href="#avg_problem_grader">avg_problem_grader</a></li>
        </ul>
      </li>
      <li class="nav-item"><a class="nav-link p-0" href="#Utility-subroutines">Utility subroutines</a>
        <ul class="nav flex-column w-100">
          <li class="nav-item"><a class="nav-link p-0" href="#pretty_print">pretty_print</a></li>
        </ul>
      </li>
    </ul>
  </li>				</ul>
			</nav>
		</div>
	</aside>
	<div class="pod-page-container d-flex">
		<div class="container-fluid p-3 h-100" id="_podtop_">


<a href="#_podtop_"><h1 id="NAME">NAME</h1></a>

<p>PGanswermacros.pl - Macros for building answer evaluators.</p>

<a href="#_podtop_"><h1 id="SYNOPSIS">SYNOPSIS</h1></a>

<p>Number Answer Evaluators:</p>

<pre><code>num_cmp()   --      uses an input hash to determine parameters

std_num_cmp(), std_num_cmp_list(), std_num_cmp_abs, std_num_cmp_abs_list()
frac_num_cmp(), frac_num_cmp_list(), frac_num_cmp_abs, frac_num_cmp_abs_list()
arith_num_cmp(), arith_num_cmp_list(), arith_num_cmp_abs, arith_num_cmp_abs_list()
strict_num_cmp(), strict_num_cmp_list(), strict_num_cmp_abs, strict_num_cmp_abs_list()

numerical_compare_with_units()      --      requires units as part of the answer
std_num_str_cmp()   --      also accepts a set of strings as possible answers</code></pre>

<p>Function Answer Evaluators:</p>

<pre><code>fun_cmp()   --      uses an input hash to determine parameters

function_cmp(), function_cmp_abs()
function_cmp_up_to_constant(), function_cmp_up_to_constant_abs()
multivar_function_cmp()</code></pre>

<p>String Answer Evaluators:</p>

<pre><code>str_cmp()   --      uses an input hash to determine parameters

std_str_cmp(), std_str_cmp_list(), std_cs_str_cmp(), std_cs_str_cmp_list()
strict_str_cmp(), strict_str_cmp_list()
ordered_str_cmp(), ordered_str_cmp_list(), ordered_cs_str_cmp(), ordered_cs_str_cmp_list()
unordered_str_cmp(), unordered_str_cmp_list(), unordered_cs_str_cmp(), unordered_cs_str_cmp_list()</code></pre>

<p>Miscellaneous Answer Evaluators:</p>

<pre><code>checkbox_cmp()
radio_cmp()</code></pre>

<a href="#_podtop_"><h1 id="DESCRIPTION">DESCRIPTION</h1></a>

<p>The macros in this file are factories which construct and return answer evaluators for checking student answers. The macros take various arguments, including the correct answer, and return an &quot;answer evaluator&quot;, which is a subroutine reference suitable for passing to the ANS* family of macro.</p>

<p>When called with the student&#39;s answer, the answer evaluator will compare this answer to the correct answer that it keeps internally and returns an AnswerHash representing the results of the comparison. Part of the answer hash is a score, which is a number between 0 and 1 representing the correctness of the student&#39;s answer. The fields of an AnswerHash are as follows:</p>

<pre><code>score                =&gt; $correctQ,
correct_ans          =&gt; $originalCorrEqn,
student_ans          =&gt; $modified_student_ans,
original_student_ans =&gt; $original_student_answer,
ans_message              =&gt; $PGanswerMessage,
type                 =&gt; &#39;typeString&#39;,
preview_text_string  =&gt; $preview_text_string,
preview_latex_string =&gt; $preview_latex_string, # optional</code></pre>

<dl>

<dt><code>$ans_hash{score}</code></dt>
<dd>

<p>a number between 0 and 1 indicating whether the answer is correct. Fractions allow the implementation of partial credit for incorrect answers.</p>

</dd>
<dt><code>$ans_hash{correct_ans}</code></dt>
<dd>

<p>The correct answer, as supplied by the instructor and then formatted. This can be viewed by the student after the answer date.</p>

</dd>
<dt><code>$ans_hash{student_ans}</code></dt>
<dd>

<p>This is the student answer, after reformatting; for example the answer might be forced to capital letters for comparison with the instructors answer. For a numerical answer, it gives the evaluated answer. This is displayed in the section reporting the results of checking the student answers.</p>

</dd>
<dt><code>$ans_hash{original_student_ans}</code></dt>
<dd>

<p>This is the original student answer. This is displayed on the preview page and may be used for sticky answers.</p>

</dd>
<dt><code>$ans_hash{ans_message}</code></dt>
<dd>

<p>Any error message, or hint provided by the answer evaluator. This is also displayed in the section reporting the results of checking the student answers.</p>

</dd>
<dt><code>$ans_hash{type}</code></dt>
<dd>

<p>A string indicating the type of answer evaluator. This helps in preprocessing the student answer for errors. Some examples: <code>&#39;number_with_units&#39;</code>, <code>&#39;function&#39;</code>, <code>&#39;frac_number&#39;</code>, <code>&#39;arith_number&#39;</code>.</p>

</dd>
<dt><code>$ans_hash{preview_text_string}</code></dt>
<dd>

<p>This typically shows how the student answer was parsed. It is displayed on the preview page. For a student answer of 2sin(3x) this would be 2*sin(3*x). For string answers it is typically the same as $ans_hash{student_ans}.</p>

</dd>
<dt><code>$ans_hash{preview_latex_string}</code></dt>
<dd>

<p>(Optional.) This is latex version of the student answer which is used to show a typeset view on the answer on the preview page. For a student answer of 2/3, this would be \frac{2}{3}.</p>

</dd>
</dl>

<a href="#_podtop_"><h1 id="FUNCTIONS">FUNCTIONS</h1></a>

<h2 id="Answer-evaluator-macros">Answer evaluator macros</h2>

<p>The answer macros have been split up into several separate files, one for each type:</p>

<p><a href="https://openwebwork.github.io/pg-docs/pod//pg/macros/answers/PGnumericevaluators.html">PGnumericevaluators.pl</a> - contains answer evaluators for evaluating numeric values, including num_cmp() and related.</p>

<p><a href="https://openwebwork.github.io/pg-docs/pod//pg/macros/answers/PGfunctionevaluators.html">PGfunctionevaluators.pl</a> - contains answer evaluators for evaluating functions, including fun_cmp() and related.</p>

<p><a href="https://openwebwork.github.io/pg-docs/pod//pg/macros/answers/PGstringevaluators.html">PGstringevaluators.pl</a> - contains answer evaluators for evaluating strings, including str_cmp() and related.</p>

<p><a href="https://openwebwork.github.io/pg-docs/pod//pg/macros/deprecated/PGtextevaluators.html">PGtextevaluators.pl</a> - contains answer evaluators that handle free response questions and questionnaires.</p>

<p><a href="https://openwebwork.github.io/pg-docs/pod//pg/macros/answers/PGmiscevaluators.html">PGmiscevaluators.pl</a> - contains answer evaluators that don&#39;t seem to fit into other categories.</p>

<h2 id="Filters">Filters</h2>

<p>A filter is a short subroutine with the following structure. It accepts an AnswerHash, followed by a hash of options. It returns an AnswerHash</p>

<pre><code>$ans_hash = filter($ans_hash, %options);</code></pre>

<p>See the AnswerHash.pm file for a list of entries which can be expected to be found in an AnswerHash, such as &#39;student_ans&#39;, &#39;score&#39; and so forth. Other entries may be present for specialized answer evaluators.</p>

<p>The hope is that a well designed set of filters can easily be combined to form a new answer_evaluator and that this method will produce answer evaluators which are are more robust than the method of copying existing answer evaluators and modifying them.</p>

<p>Here is an outline of how a filter is constructed:</p>

<pre><code>sub filter{
    my $rh_ans = shift;
    my %options = @_;
    assign_option_aliases(\%options,
            &#39;alias1&#39;    =&gt; &#39;option5&#39;
            &#39;alias2&#39;    =&gt; &#39;option7&#39;
    );
    set_default_options(\%options,
            &#39;_filter_name&#39;    =&gt;    &#39;filter&#39;,
            &#39;option5&#39;        =&gt;  .0001,
            &#39;option7&#39;        =&gt;    &#39;ascii&#39;,
            &#39;allow_unknown_options    =&gt;    0,
    }
    .... body code of filter .......
        if ($error) {
            $rh_ans-&gt;throw_error(&quot;FILTER_ERROR&quot;, &quot;Something went wrong&quot;);
            # see AnswerHash.pm for details on using the throw_error method.

    $rh_ans;  #reference to an AnswerHash object is returned.
}</code></pre>

<h3 id="compare_numbers">compare_numbers</h3>

<h3 id="std_num_filter">std_num_filter</h3>

<pre><code>std_num_filter($rh_ans, %options)
returns $rh_ans</code></pre>

<p>Replaces some constants using math_constants, then evaluates a perl expression.</p>

<h3 id="std_num_array_filter">std_num_array_filter</h3>

<pre><code>std_num_array_filter($rh_ans, %options)
returns $rh_ans</code></pre>

<p>Assumes the {student_ans} field is a numerical array, and applies BOTH check_syntax and std_num_filter to each element of the array. Does it&#39;s best to generate sensible error messages for syntax errors. A typical error message displayed in {studnet_ans} might be ( 56, error message, -4).</p>

<h2 id="function_from_string2">function_from_string2</h2>

<h2 id="is_zero_array"><code>is_zero_array</code></h2>

<h2 id="best_approx_parameters"><code>best_approx_parameters</code></h2>

<pre><code>best_approx_parameters($rh_ans,%options);   # requires the following fields in $rh_ans
                      {rf_student_ans}      # reference to the test answer
                      {rf_correct_ans}      # reference to the comparison answer
                      {evaluation_points},  # an array of row vectors indicating the points
                                            # to evaluate when comparing the functions

                       %options             # debug =&gt; 1   gives more error answers
                                            # param_vars =&gt; [&#39;&#39;]  additional parameters used to adapt to function
                       )</code></pre>

<p>The parameters for the comparison function which best approximates the test_function are stored in the field {ra_parameters}.</p>

<p>The last $dim_of_parms_space variables are assumed to be parameters, and it is also assumed that the function \&amp;comparison_fun depends linearly on these variables. This function finds the values for these parameters which minimizes the Euclidean distance (L2 distance) between the test function and the comparison function and the test points specified by the array reference \@rows_of_test_points. This is assumed to be an array of arrays, with the inner arrays determining a test point.</p>

<p>The comparison function should have $dim_of_params_space more input variables than the test function.</p>

<h4 id="calculate_difference_vector"><code>calculate_difference_vector</code></h4>

<pre><code>calculate_difference_vector( $ans_hash, %options);

    {rf_student_ans},     # a reference to the test function
    rf_correct_ans},      # a reference to the correct answer function
    evaluation_points},   # an array of row vectors indicating the points
                          # to evaluate when comparing the functions
    ra_parameters}        # these are the (optional) additional inputs to
                          # the comparison function which adapt it properly
                          # to the problem at hand.

    %options               # mode =&gt; &#39;rel&#39;  specifies that each element in the
                           # difference matrix is divided by the correct answer.
                           # unless the correct answer is nearly 0.</code></pre>

<h3 id="fix_answer_for_display"><code>fix_answer_for_display</code></h3>

<h3 id="evaluatesToNumber"><code>evaluatesToNumber</code></h3>

<h4 id="is_numeric_expression">is_numeric_expression</h4>

<h3 id="is_a_number"><code>is_a_number</code></h3>

<h3 id="is_a_fraction"><code>is_a_fraction</code></h3>

<h3 id="phase_pi"><code>phase_pi</code></h3>

<p>I often discovered that the answers I was getting, when using the arctan function would be off by phases of pi, which for the tangent function, were equivalent values. This method allows for this.</p>

<h4 id="is_an_arithemetic_expression"><code>is_an_arithemetic_expression</code></h4>

<h3 id="math_constants"><code>math_constants</code></h3>

<p>replaces pi, e, and ^ with their Perl equivalents if useBaseTenLog is non-zero, convert log to logten</p>

<h3 id="is_array"><code>is_array</code></h3>

<p><code>is_array($rh_ans)</code></p>

<p>returns:</p>

<p><code>$rh_ans</code>. Throws error &quot;NOTARRAY&quot; if this is not an array</p>

<h3 id="check_syntax"><code>check_syntax</code></h3>

<p><code>check_syntax( $rh_ans, %options)</code></p>

<p>returns an answer hash.</p>

<p>The input has been transformed, changing 7pi to 7*pi or 7x to 7*x. Syntax error messages may be generated and stored in student_ans Additional syntax error messages are stored in {ans_message} and duplicated in {error_message}</p>

<h3 id="check_strings"><code>check_strings</code></h3>

<p><code>check_strings ($rh_ans, %options)</code></p>

<p>returns $rh_ans</p>

<h3 id="check_units"><code>check_units</code></h3>

<p><code>check_strings ($rh_ans, %options)</code></p>

<p>returns <code>$rh_ans</code></p>

<h3 id="std_problem_grader"><code>std_problem_grader</code></h3>

<p>This is an all-or-nothing grader. A student must get all parts of the problem write before receiving credit. You should make sure to use this grader on multiple choice and true-false questions, otherwise students will be able to deduce how many answers are correct by the grade reported by webwork.</p>

<pre><code>install_problem_grader(~~&amp;std_problem_grader);</code></pre>

<h3 id="std_problem_grader2"><code>std_problem_grader2</code></h3>

<p>This is an all-or-nothing grader. A student must get all parts of the problem write before receiving credit. You should make sure to use this grader on multiple choice and true-false questions, otherwise students will be able to deduce how many answers are correct by the grade reported by webwork.</p>

<pre><code>install_problem_grader(~~&amp;std_problem_grader2);</code></pre>

<p>The only difference between the two versions is at the end of the subroutine, where std_problem_grader2 records the attempt only if there have been no syntax errors, whereas std_problem_grader records it regardless.</p>

<h3 id="avg_problem_grader"><code>avg_problem_grader</code></h3>

<p>This grader gives a &quot;weighted&quot; average score to the problem and is the default grader.</p>

<p>The grader can be selected by calling</p>

<pre><code>install_problem_grader(~~&amp;avg_problem_grader);</code></pre>

<p>However, since this is the default grader, that is not necessary to use this grader.</p>

<p>Each answer is assigned a weight (the default is 1). The score is then the sum of the product of the weights and scores for the correct answers divided by the total of the weights for all answers. (To assign weights as percentages, use integers that add up to 100. For example, use 40 and 60 for the weights for two answers.) Assign weights to answers using the <code>cmp</code> option <code>weight =&gt; n</code>. For example, in PGML create the answer rule with</p>

<pre><code>[_]{$answer}{10}{ cmp_options =&gt; { weight =&gt; 40 } }</code></pre>

<p>With the classic <code>ANS</code> method call</p>

<pre><code>ANS($answer-&gt;cmp(weight =&gt; 40);</code></pre>

<p>This grader also allows for one &quot;goal&quot; answer that is answered correctly to automatically give credit for one or more other &quot;optional&quot; answers. This way, if there are several &quot;optional&quot; answers leading up to the &quot;goal&quot; answer, and the student produces the &quot;goal&quot; answer by some other means and does not answer the &quot;optional&quot; answers, the student can be given full credit for the problem anyway. To use this feature use the <code>credit</code> option of the <code>cmp</code> method for the &quot;goal&quot; answer. For example, <code>credit =&gt; $answer1Name</code> or <code>credit =&gt; [ $answer1Name, $answer2Name, ... ]</code>, where <code>$answer1Name</code>, <code>$answer2Name</code>, etc., are the names of the &quot;optional&quot; answers that will be given credit if the &quot;goal&quot; answer is correct. Note that the other answers must be assigned names either by calling <code>NAMED_ANS_RULE</code> and <code>NAMED_ANS</code>, or by creating the answer rule in PGML with <code>[_]{$answer1}{15}{$answer1Name}</code>, for example. The answer names should be generated by calling <code>NEW_ANS_NAME</code> (for example, <code>$answer1Name = NEW_ANS_NAME()</code>) rather than being made up. Otherwise the problem will fail to work in many situations (for example, in tests). For example, to set this up in PGML use</p>

<pre><code>BEGIN_PGML
Optional Answer 1: [_]{$answer1}{10}{$answer1Name = NEW_ANS_NAME()}

Optional Answer 2: [_]{$answer2}{10}{$answer2Name = NEW_ANS_NAME()}

Goal: [_]{$answer3}{10}{ cmp_options =&gt; { credit =&gt; [ $answer1Name, $answer2Name ] } }
END_PGML</code></pre>

<p>Note that the <code>credit</code> and <code>weight</code> options can be used together. For example:</p>

<pre><code>BEING_PGML
Optional Answer: [_]{$optional}{10}{$optionalName = NEW_ANS_NAME()}{{ weight =&gt; 20 }}

Goal: [_]{$goalAnswer}{10}{ cmp_options =&gt; { credit =&gt; $optionalName, weight =&gt; 80 } }
END_PGML</code></pre>

<p>This way, if the &quot;optional&quot; answer is correct but the &quot;goal&quot; answer is not, the problem score will be 20%, but if the &quot;goal&quot; answer is correct, the problem score will be 100%.</p>

<p>One caveat to keep in mind is that credit is given to an &quot;optional&quot; answer ONLY if the answer is left blank (or is actually correct). Credit will NOT be given if an &quot;optional&quot; answer is incorrect, even if the &quot;goal&quot; answer IS correct.</p>

<p>When credit is given to an &quot;optional&quot; answer due to the &quot;goal&quot; answer being correct, a message will be added to the &quot;optional&quot; answer stating, &quot;This answer was marked correct because the primary answer is correct.&quot;</p>

<h2 id="Utility-subroutines">Utility subroutines</h2>

<h3 id="pretty_print"><code>pretty_print</code></h3>

<p>Usage:</p>

<pre><code>warn pretty_print($rh_hash_input);
TEXT(pretty_print($ans_hash));
TEXT(~~%envir);</code></pre>

<p>This can be very useful for printing out messages about objects while debugging</p>

		</div>
	</div>
</body>
</html>
